---
title: "NHS-Winter-SitReps"
author: "Yasser"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
extrafont::loadfonts(device="win")

# Required packages

library(tidyverse)
library(readxl)
library(lubridate)
library(geojsonio)
library(broom)
library(maptools)


```

Download data from NHS Digital.

```{r}
url <- "https://www.england.nhs.uk/statistics/wp-content/uploads/sites/2/2021/02/UEC-Daily-SitRep-Acute-Web-File-Timeseries-1.xlsx"
filename <- "Winter-data-timeseries.xlsx"
download.file(url, destfile = filename, mode = "wb")

```
Tackling multi-line headers with merged cells.
Start with General and Acute Beds and the Beds Occupied by Long Stay Patients 

These two tabs contain metadata in the first 13 lines followed by two line headers. Several columns containing variables (second header line) are grouped within dates (first header line) and the cells around the dates are merged. Also some empty columns and rows.

First explore the data file as is...

```{r}
example_indicator <- "G&A beds"

# First line containes dates in merged cells (5 cells merged each in this case)
header_1 <- read_xlsx(path = filename, sheet = example_indicator, 
                      skip = 13, col_names = FALSE, 
                      n_max = 1)

# Second line contains variable names
header_2 <- read_xlsx(path = filename, sheet = example_indicator, 
                      skip = 14, col_names = FALSE, 
                      n_max = 1)
```

Check dimensions of dataframes.

```{r}
dim(header_1) # 167

dim(header_2) # 172

# there is a difference in the number of columns - header_1 is shorter by 5
# first 10 columns from header_1
header_1[1:10]
# starts with the date colum, we lost the few columns that contain trust code, name etc. in line 2

# End of header 1
header_1[(ncol(header_1)-10):ncol(header_1)]

```

```{r}
# try the same with header)2

header_2[1:10]
# End
header_2[(ncol(header_1)-10):ncol(header_1)]

```

Header_1 was short due to :

In the Excel sheet, the first few cells in this line were empty and when the line was read in, they were converted to NA. The read_xlsx() function then discarded these empty columns (probably) because they were at the beginning.
There were also some merged cells. During import they were separated and, if empty, converted to NA . Empty columns at the end of the header line also seem to be discarded by read_xlsx().

Did the following to tidy the data appropriately.

```{r}
# this extracts all the raw data, without columns
data <- read_xlsx(path = filename, sheet = "G&A beds", skip = 15, col_names = FALSE)
data
```

```{r}
# Extract first header line containing dates and fill the gaps: 
# Read 2 lines but guess the data types only from the first row
# Based on the first line, the function expects dates and 
# convert the second row to NA 
# As a result, the right length is preserved. 

header_1 <- read_xlsx(path = filename, sheet = "G&A beds", skip = 13, col_names = FALSE, n_max = 2, guess_max = 1)
header_1
```

```{r}
# this step convert header_1 to columns, fill in the gaps and convert into vector
header_1 <- header_1 %>% 
    t() %>% 
    as.data.frame() %>% 
    fill(.,'V1') 

header_1 <- as.character(header_1$V1)  
  
header_1 # now as character vector

```

```{r}
# Extract second header and convert into vector
header_2 <- read_xlsx(path = filename, sheet = "G&A beds", skip = 14, col_names = FALSE, n_max = 1)
header_2

```

```{r}
# Concatenating headers to create column names
# Replace NAs with a placeholder, otherwise concatenation fails
column_names <- str_c(str_replace_na(header_1, "placeholder"), str_replace_na(header_2, "placeholder"), sep = "_")
column_names
```

```{r}
# Add column names to data and tidy
names(data) <- tolower(column_names)
names(data) <- gsub(" ", ".", names(data))
names(data) <- gsub("placeholder_", "", names(data))
names(data) <- gsub("'", "", names(data))
names(data) <- gsub("<", "less.than", names(data))
names(data) <- gsub(">", "more.than", names(data))
data
```

```{r}
# Tidy table
data_tidy <- data %>% 
  select(-na) %>% # removes empty column here named "na"
  filter(!is.na(name)) %>% 
  # Separate variables and dates
  #gather(-1, -2, -3, key = "date_type", value = 'value')
  pivot_longer(4:last_col(), names_to = "date_type", values_to = "value") %>% # this has replaced the gather function
  separate(date_type, into = c("date", "type"), sep = "_") %>%
  #spread(key = 'type', value = 'value')
  pivot_wider(names_from = "type", values_from = "value") %>% # this has replaced spread
  # convert to the right variable types
  mutate(date = as.Date(date)) %>%
  mutate_at(vars(5:ncol(.)), funs(as.numeric))
  
```
```{r}
# all combined in the following function:

import_sitrep <- function(file, indicator){
  
  data <- read_xlsx(path = file, sheet = indicator, skip = 15, col_names = FALSE) 
  
  # Extract first header line containing dates and fill the gaps: 
  # Read 2 lines but guess the data types only from the first row
  # R will be looking for dates and convert the second row
  # to NA but the right length will be preserved. 
  header_1 <- read_xlsx(path = file, sheet = indicator, skip = 13, col_names = FALSE, n_max = 2, guess_max = 1)
  
  # Convert to columns, fill in the gaps and convert into vector
  header_1 <- header_1 %>% 
    t() %>% 
    as.data.frame() %>% 
    fill(.,'V1') 
  header_1 <- as.character(header_1$V1)  
  
  # Extract second header and convert into vector
  header_2 <- read_xlsx(path = file, sheet = indicator, skip = 14, col_names = FALSE, n_max = 1)
  header_2 <- unname(unlist(header_2[1,]))
  
  # Concatenating headers to create column names
  # Replace NAs with a placeholder, otherwise concatenation fails
  column_names <- str_c(str_replace_na(header_1, "placeholder"), str_replace_na(header_2, "placeholder"), sep = "_")
  
  # Add column names to data and tidy
  names(data) <- tolower(column_names)
  names(data) <- gsub(" ", ".", names(data))
  names(data) <- gsub("placeholder_", "", names(data))
  names(data) <- gsub("'", "", names(data))
  names(data) <- gsub("<", "less.than", names(data))
  names(data) <- gsub(">", "more.than", names(data))
  
  # Tidy up table
  data_tidy <- data %>% 
    # remove empty column and line
    select(-placeholder) %>% 
    filter(!is.na(name)) %>%
    # Separate variables and dates
    #gather(-1, -2, -3, key = "date_type", value = 'value')
    pivot_longer(4:last_col(), names_to = "date_type", values_to = "value") %>% # this has replaced the gather function
    separate(date_type, into = c("date", "type"), sep = "_") %>%
    #spread(key = 'type', value = 'value')
    pivot_wider(names_from = "type", values_from = "value") %>% # this has replaced spread
    # convert to the right variable types
    mutate(date = as.Date(date)) %>%
    mutate_at(vars(5:ncol(.)), funs(as.numeric))
  
  data_tidy
}
```

For an overview of the pivot functions: https://tidyr.tidyverse.org/articles/pivot.html

And overview of tidy-select `last_col()` https://tidyr.tidyverse.org/reference/tidyr_tidy_select.html

And overview of mutate multiple columns `mutate_at` https://dplyr.tidyverse.org/reference/mutate_all.html

We can now use this function to read and combine the following tabs: ‘General and acute beds’ and ‘Beds occupied by long-stay patients’

```{r}
sheets_to_import <- c("G&A beds", "Beds Occ by long stay patients")

Sitrep_daily <- sheets_to_import %>% 
  map(import_sitrep,
      file = filename) %>%
  reduce(left_join, 
         by = c("nhs.england.region", "code", "name", "date"))

dim(Sitrep_daily)
head(Sitrep_daily)
# there are missing values in the length of stay columns as this data didn't start until 30th Nov 2020
```

Overview of `reduce()` https://blog.zhaw.ch/datascience/r-reduce-applys-lesser-known-brother/

Data is now tidy.

Data Cleaning:

Will remove some children hospitals due to difference patient profiles.

```{r}
# children's hospitals to be exlcuded for aggregation by STP
trusts_to_exclude_for_aggregation <- c("RQ3", "RBS", "RCU")
#Birmingham Women’s and Children’s NHS Foundation Trust (code RQ3), Alder Hey Children’s NHS Foundation Trust (RBS) and Sheffield Children’s NHS Foundation Trust (RCU)
```

Next step is to remove missing values, which can either be NAs or 0s - need to determine method.

The authors of the original analysis described as follows:

 - How likely is a ‘zero event’ for an indicator? For example, when counting beds in a large hospital the likelihood of having zero open seems small, but when counting long-stay patients having none seems possible.
 - How consistent is the zero value, in that trust, over time? Or in plain English: does the value jump from a higher number to zero (and back) or is it hovering somewhere close to zero.

Following analysis finds and resolves these issues:

### Finding longer periods of missing data

The author used the following criteria to exclude Trusts:

 - Any missing values in any indicator on 4 or more consecutive days.
 - Only in indicators where zeros would not be expected.
 - This was due to the need to calculate weekly averages.
 
Method to identify how many consecutive days were zero or NA:

```{r}
# Only check variables that are not derived from other variables
cols_to_check_1 <- c("total.beds.open", "total.beds.occd")

cols_to_check_2 <- c("more.than.7.days", "more.than.14.days", "more.than.21.days")
# Separated the above into two as the length of stay variables in new data only start at 30th Nov

# Find values that are 0 or NA
# within any trust/variable combination

Sitrep_missing_or_zero <- Sitrep_daily %>% 
  filter(!str_detect(name,"ENGLAND")) %>% # altered to reflect change in data since 18/19
  select(!(all_of(cols_to_check_2))) %>% # only select variables that begin 2nd Nov first
  #gather(cols_to_check, key = "variable", value = "value")
  pivot_longer(all_of(cols_to_check_1), names_to = "variable", values_to = "value") %>% # replaced gather with pivot_longer
  filter(value == 0 | is.na(value)) %>%
  # Sort and assign a period ID to consecutive days
  arrange(code, variable, date) %>%
  group_by(code, variable) %>%
  mutate(diff = c(0, diff(date)),
         periodID = 1 + cumsum(diff > 1))

# Summarise consecutive days that variables are missing
Days_missing <- Sitrep_missing_or_zero %>% 
  # remove trusts we already decided to exclude
  filter(!is.element(code, trusts_to_exclude_for_aggregation)) %>% 
  group_by(code, variable, periodID) %>% 
  summarise(days = as.numeric((last(date) - first(date) + 1))) %>%
  arrange(desc(days))

Days_missing
```


```{r}
# Now do the same with the length of stay variables
Sitrep_missing_or_zero_LoS <- Sitrep_daily %>% 
  filter(!str_detect(name,"ENGLAND"), date >= '2020-11-30') %>% # altered to reflect change in data since 18/19 and filters data for after 30th Nov (start date of LoS data)
  select(!(all_of(cols_to_check_1))) %>% # only select length of stay variables
  #gather(cols_to_check, key = "variable", value = "value")
  pivot_longer(all_of(cols_to_check_2), names_to = "variable", values_to = "value") %>% # replaced gather with pivot_longer
  filter(value == 0 | is.na(value)) %>%
  # Sort and assign a period ID to consecutive days
  arrange(code, variable, date) %>%
  group_by(code, variable) %>%
  mutate(diff = c(0, diff(date)),
         periodID = 1 + cumsum(diff > 1))

# Summarise consecutive days that variables are missing
Days_missing_LoS <- Sitrep_missing_or_zero_LoS %>% 
  # remove trusts we already decided to exclude
  filter(!is.element(code, trusts_to_exclude_for_aggregation)) %>% 
  group_by(code, variable, periodID) %>% 
  summarise(days = as.numeric((last(date) - first(date) + 1))) %>%
  arrange(desc(days))

Days_missing_LoS
```
 
```{r}
# combine the two day_missing tables
Days_missing_combined <- union_all(Days_missing, Days_missing_LoS) %>%
  # large number of missing values from numerous hospitals
  inner_join(select(Sitrep_daily, c("code", "name")), by = "code") %>%
  unique()
Days_missing_combined
```

```{r}
trusts_to_exclude <- Days_missing_combined %>%
  filter(days >= 4) %>% 
  pull(code) %>%
  unique()

Days_missing_combined %>%
  filter(days >= 4) %>% 
  pull(name) %>%
  unique()

# Trusts excluded are mainly those seemed to start submitting their data late.
```

```{r}
# remove from the data
Sitrep_daily <- Sitrep_daily %>% 
   filter(!code %in% trusts_to_exclude)

dim(Sitrep_daily)  
```

```{r}
Sitrep_daily
# there remains the difference between when the total beds data starts and the length of stay data starts - will leave the data like this for now and adjust
# later if needed.

```

### Dealing with shorter gaps

Next - check how many missing or zero values are left:

```{r}
# How many 1,2 and 3-day gaps are there?
Days_missing_combined %>% 
  filter(!code %in% trusts_to_exclude) %>% 
  group_by(days) %>% 
  count()
```

```{r}
# How are they distributed between trusts and variables?
Days_missing_combined %>% 
  filter(!code %in% trusts_to_exclude) %>% 
  group_by(code, variable) %>% 
  count() %>% 
  pivot_wider(names_from = "variable", values_from = "n")

#pivot_wider(names_from = "type", values_from = "value")
```

Most of the remaining gaps were mostly found in variables relating to long-stay patients. To judge whether these looked like real ‘zero events’ or were more likely to be reporting errors, had a further look at the data:

```{r, fig.width=8}
cols_to_check_all <- c(cols_to_check_1, cols_to_check_2)
# Extract and plot trusts with zeros in their data. 
Sitrep_daily_small_gaps <- Sitrep_daily %>% 
  select(code, date, cols_to_check_all) %>% 
  filter(code %in% Days_missing_combined$code & !code %in% trusts_to_exclude) %>%
  pivot_longer(cols_to_check_all, names_to = "variable", values_to = "value")

ggplot(Sitrep_daily_small_gaps, aes(x = date, y = value, group = code, color = code)) +
  theme_bw() +
  geom_line() +
  geom_point(size = 1) +
  facet_wrap("variable", scales = "free_y") 
```

As the gaps above were likely errors, not actual values, they will be replaced with NAs. Note the length of stay variables started later than the bed occupancy variables.

```{r}
# Create a 'clean' version where 0s were replaced with NA
Sitrep_daily[cols_to_check_all] <- na_if(Sitrep_daily[cols_to_check_all], 0)
```


### Feature engineering

- Adding organisational information on sustainability and transformation partnerships (STPs)

The hospital trusts here are mapped to STPs, which provide an aggregated way to visualise the data.

- First, get STP level data:

The following connects to an API, which turned out not to have the relevant detail

```{r}
# from tutorial: https://www.dataquest.io/blog/r-api-tutorial/
first_api <- httr::GET("https://directory.spineservices.nhs.uk/ORD/2-0-0/organisations?PrimaryRoleId=RO197")

jsonlite::fromJSON(rawToChar(first_api$content))
```

The following file does though:

```{r}
url_stp <- "https://digital.nhs.uk/binaries/content/assets/website-assets/services/ods/data-downloads-other-nhs-organisations/stp-partners-master.xlsx"
filename_stp <- "STP-Lookup.xlsx"
download.file(url_stp, destfile = filename_stp, mode = "wb")

```
```{r}
# Import STP data:

data_stp <- read_xlsx(path = filename_stp, sheet = "Current STPs", skip = 4)
data_stp <- data_stp %>% 
  select(`NHS England Region`, `STP Name`, `ONS STP Code`, Trusts, `ODS Trust Code`) %>%
  rename(code = `ODS Trust Code`, STP_Code = `ONS STP Code`) %>%
  filter(!is.na(Trusts))
  

```

```{r}
# Now merge with hospital data:
Sitrep_daily <- Sitrep_daily %>% 
  left_join(select(data_stp, code, `STP Name`, STP_Code), by = "code")

```


- Adding rates of bed occupancy by length of stay

To obtain more comparable data, derived the fraction of occupied beds, which are occupied by long-stay patients over 7, 14 or 21 days:

```{r}
# given the mismatch between bed occupancy data and length of stay data starting date, will filter for data from 2020-11-30, from when both complete.
Sitrep_daily_rates <- Sitrep_daily %>%
  filter(date >= "2020-11-30") %>%
  mutate(more.than.7.rate = more.than.7.days / total.beds.occd,
         more.than.14.rate = more.than.14.days / total.beds.occd,
         more.than.21.rate = more.than.21.days / total.beds.occd)
Sitrep_daily_rates
```
### Aggregation by STP


