---
title: "NHS-Winter-SitReps"
author: "Yasser"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
extrafont::loadfonts(device="win")

# Required packages

library(tidyverse)
library(readxl)
library(lubridate)
library(geojsonio)
library(broom)
library(maptools)


```

Download data from NHS Digital.

```{r}
url <- "https://www.england.nhs.uk/statistics/wp-content/uploads/sites/2/2021/02/UEC-Daily-SitRep-Acute-Web-File-Timeseries.xlsx"
filename <- "Winter-data-timeseries.xlsx"
download.file(url, destfile = filename, mode = "wb")

```
Tackling multi-line headers with merged cells.
Start with General and Acute Beds and the Beds Occupied by Long Stay Patients 

These two tabs contain metadata in the first 13 lines followed by two line headers. Several columns containing variables (second header line) are grouped within dates (first header line) and the cells around the dates are merged. Also some empty columns and rows.

First explore the data file as is...

```{r}
example_indicator <- "G&A beds"

# First line containes dates in merged cells (5 cells merged each in this case)
header_1 <- read_xlsx(path = filename, sheet = example_indicator, 
                      skip = 13, col_names = FALSE, 
                      n_max = 1)

# Second line contains variable names
header_2 <- read_xlsx(path = filename, sheet = example_indicator, 
                      skip = 14, col_names = FALSE, 
                      n_max = 1)
```

Check dimensions of dataframes.

```{r}
dim(header_1) # 167

dim(header_2) # 172

# there is a difference in the number of columns - header_1 is shorter by 5
# first 10 columns from header_1
header_1[1:10]
# starts with the date colum, we lost the few columns that contain trust code, name etc. in line 2

# End of header 1
header_1[(ncol(header_1)-10):ncol(header_1)]

```

```{r}
# try the same with header)2

header_2[1:10]
# End
header_2[(ncol(header_1)-10):ncol(header_1)]

```

Header_1 was short due to :

In the Excel sheet, the first few cells in this line were empty and when the line was read in, they were converted to NA. The read_xlsx() function then discarded these empty columns (probably) because they were at the beginning.
There were also some merged cells. During import they were separated and, if empty, converted to NA . Empty columns at the end of the header line also seem to be discarded by read_xlsx().

Did the following to tidy the data appropriately.

```{r}
# this extracts all the raw data, without columns
data <- read_xlsx(path = filename, sheet = "G&A beds", skip = 15, col_names = FALSE)
data
```

```{r}
# Extract first header line containing dates and fill the gaps: 
# Read 2 lines but guess the data types only from the first row
# Based on the first line, the function expects dates and 
# convert the second row to NA 
# As a result, the right length is preserved. 

header_1 <- read_xlsx(path = filename, sheet = "G&A beds", skip = 13, col_names = FALSE, n_max = 2, guess_max = 1)
header_1
```

```{r}
# this step convert header_1 to columns, fill in the gaps and convert into vector
header_1 <- header_1 %>% 
    t() %>% 
    as.data.frame() %>% 
    fill(.,'V1') 

header_1 <- as.character(header_1$V1)  
  
header_1 # now as character vector

```

```{r}
# Extract second header and convert into vector
header_2 <- read_xlsx(path = filename, sheet = "G&A beds", skip = 14, col_names = FALSE, n_max = 1)
header_2

```

```{r}
# Concatenating headers to create column names
# Replace NAs with a placeholder, otherwise concatenation fails
column_names <- str_c(str_replace_na(header_1, "placeholder"), str_replace_na(header_2, "placeholder"), sep = "_")
column_names
```

```{r}
# Add column names to data and tidy
names(data) <- tolower(column_names)
names(data) <- gsub(" ", ".", names(data))
names(data) <- gsub("placeholder_", "", names(data))
names(data) <- gsub("'", "", names(data))
names(data) <- gsub("<", "less.than", names(data))
names(data) <- gsub(">", "more.than", names(data))
data
```

```{r}
# Tidy table
data_tidy <- data %>% 
  select(-na) %>% # removes empty column here named "na"
  filter(!is.na(name)) %>% 
  # Separate variables and dates
  #gather(-1, -2, -3, key = "date_type", value = 'value')
  pivot_longer(4:last_col(), names_to = "date_type", values_to = "value") %>% # this has replaced the gather function
  separate(date_type, into = c("date", "type"), sep = "_") %>%
  #spread(key = 'type', value = 'value')
  pivot_wider(names_from = "type", values_from = "value") %>% # this has replaced spread
  # convert to the right variable types
  mutate(date = as.Date(date)) %>%
  mutate_at(vars(5:ncol(.)), funs(as.numeric))
  
```
```{r}
# all combined in the following function:

import_sitrep <- function(file, indicator){
  
  data <- read_xlsx(path = file, sheet = indicator, skip = 15, col_names = FALSE) 
  
  # Extract first header line containing dates and fill the gaps: 
  # Read 2 lines but guess the data types only from the first row
  # R will be looking for dates and convert the second row
  # to NA but the right length will be preserved. 
  header_1 <- read_xlsx(path = file, sheet = indicator, skip = 13, col_names = FALSE, n_max = 2, guess_max = 1)
  
  # Convert to columns, fill in the gaps and convert into vector
  header_1 <- header_1 %>% 
    t() %>% 
    as.data.frame() %>% 
    fill(.,'V1') 
  header_1 <- as.character(header_1$V1)  
  
  # Extract second header and convert into vector
  header_2 <- read_xlsx(path = file, sheet = indicator, skip = 14, col_names = FALSE, n_max = 1)
  header_2 <- unname(unlist(header_2[1,]))
  
  # Concatenating headers to create column names
  # Replace NAs with a placeholder, otherwise concatenation fails
  column_names <- str_c(str_replace_na(header_1, "placeholder"), str_replace_na(header_2, "placeholder"), sep = "_")
  
  # Add column names to data and tidy
  names(data) <- tolower(column_names)
  names(data) <- gsub(" ", ".", names(data))
  names(data) <- gsub("placeholder_", "", names(data))
  names(data) <- gsub("'", "", names(data))
  names(data) <- gsub("<", "less.than", names(data))
  names(data) <- gsub(">", "more.than", names(data))
  
  # Tidy up table
  data_tidy <- data %>% 
    # remove empty column and line
    select(-placeholder) %>% 
    filter(!is.na(name)) %>%
    # Separate variables and dates
    #gather(-1, -2, -3, key = "date_type", value = 'value')
    pivot_longer(4:last_col(), names_to = "date_type", values_to = "value") %>% # this has replaced the gather function
    separate(date_type, into = c("date", "type"), sep = "_") %>%
    #spread(key = 'type', value = 'value')
    pivot_wider(names_from = "type", values_from = "value") %>% # this has replaced spread
    # convert to the right variable types
    mutate(date = as.Date(date)) %>%
    mutate_at(vars(5:ncol(.)), funs(as.numeric))
  
  data_tidy
}
```

For an overview of the pivot functions: https://tidyr.tidyverse.org/articles/pivot.html

And overview of tidy-select `last_col()` https://tidyr.tidyverse.org/reference/tidyr_tidy_select.html

And overview of mutate multiple columns `mutate_at` https://dplyr.tidyverse.org/reference/mutate_all.html

We can now use this function to read and combine the following tabs: ‘General and acute beds’ and ‘Beds occupied by long-stay patients’

```{r}
sheets_to_import <- c("G&A beds", "Beds Occ by long stay patients")

Sitrep_daily <- sheets_to_import %>% 
  map(import_sitrep,
      file = filename) %>%
  reduce(left_join, 
         by = c("nhs.england.region", "code", "name", "date"))

dim(Sitrep_daily)
head(Sitrep_daily)
# there are missing values in the length of stay columns as this data didn't start until 30th Nov 2020
```

Overview of `reduce()` https://blog.zhaw.ch/datascience/r-reduce-applys-lesser-known-brother/

Data is now tidy.

Data Cleaning:

Will remove some children hospitals due to difference patient profiles.

```{r}
# children's hospitals to be exlcuded for aggregation by STP
trusts_to_exclude_for_aggregation <- c("RQ3", "RBS", "RCU")
#Birmingham Women’s and Children’s NHS Foundation Trust (code RQ3), Alder Hey Children’s NHS Foundation Trust (RBS) and Sheffield Children’s NHS Foundation Trust (RCU)
```

Next step is to remove missing values, which can either be NAs or 0s - need to determine method.

The authors of the original analysis described as follows:

 - How likely is a ‘zero event’ for an indicator? For example, when counting beds in a large hospital the likelihood of having zero open seems small, but when counting long-stay patients having none seems possible.
 - How consistent is the zero value, in that trust, over time? Or in plain English: does the value jump from a higher number to zero (and back) or is it hovering somewhere close to zero.

Following analysis finds and resolves these issues:

### Finding longer periods of missing data

The author used the following criteria to exclude Trusts:

 - Any missing values in any indicator on 4 or more consecutive days.
 - Only in indicators where zeros would not be expected.
 - This was due to the need to calculate weekly averages.
 
Method to identify how many consecutive days were zero or NA:

```{r}
# Only check variables that are not derived from other variables
cols_to_check_1 <- c("total.beds.open", "total.beds.occd")

cols_to_check_2 <- c("more.than.7.days", "more.than.14.days", "more.than.21.days")
# Separated the above into two as the length of stay variables in new data only start at 30th Nov

# Find values that are 0 or NA
# within any trust/variable combination

Sitrep_missing_or_zero <- Sitrep_daily %>% 
  filter(!str_detect(name,"ENGLAND")) %>% # altered to reflect change in data since 18/19
  select(!(all_of(cols_to_check_2))) %>% # only select variables that begin 2nd Nov first
  #gather(cols_to_check, key = "variable", value = "value")
  pivot_longer(all_of(cols_to_check_1), names_to = "variable", values_to = "value") %>% # replaced gather with pivot_longer
  filter(value == 0 | is.na(value)) %>%
  # Sort and assign a period ID to consecutive days
  arrange(code, variable, date) %>%
  group_by(code, variable) %>%
  mutate(diff = c(0, diff(date)),
         periodID = 1 + cumsum(diff > 1))

# Summarise consecutive days that variables are missing
Days_missing <- Sitrep_missing_or_zero %>% 
  # remove trusts we already decided to exclude
  filter(!is.element(code, trusts_to_exclude_for_aggregation)) %>% 
  group_by(code, variable, periodID) %>% 
  summarise(days = as.numeric((last(date) - first(date) + 1))) %>%
  arrange(desc(days))

Days_missing
```


```{r}
# Now do the same with the length of stay variables
Sitrep_missing_or_zero_LoS <- Sitrep_daily %>% 
  filter(!str_detect(name,"ENGLAND"), date >= '2020-11-30') %>% # altered to reflect change in data since 18/19 and filters data for after 30th Nov (start date of LoS data)
  select(!(all_of(cols_to_check_1))) %>% # only select length of stay variables
  #gather(cols_to_check, key = "variable", value = "value")
  pivot_longer(all_of(cols_to_check_2), names_to = "variable", values_to = "value") %>% # replaced gather with pivot_longer
  filter(value == 0 | is.na(value)) %>%
  # Sort and assign a period ID to consecutive days
  arrange(code, variable, date) %>%
  group_by(code, variable) %>%
  mutate(diff = c(0, diff(date)),
         periodID = 1 + cumsum(diff > 1))

# Summarise consecutive days that variables are missing
Days_missing_LoS <- Sitrep_missing_or_zero_LoS %>% 
  # remove trusts we already decided to exclude
  filter(!is.element(code, trusts_to_exclude_for_aggregation)) %>% 
  group_by(code, variable, periodID) %>% 
  summarise(days = as.numeric((last(date) - first(date) + 1))) %>%
  arrange(desc(days))

Days_missing_LoS
```
 
```{r}
# combine the two day_missing tables
Days_missing_combined <- union_all(Days_missing, Days_missing_LoS) %>%
  filter(days >= 4) %>%
  # large number of missing values from numerous hospitals
  inner_join(select(Sitrep_daily, c("code", "name")), by = "code") %>%
  unique()
Days_missing_combined
```

```{r}
trusts_to_exclude <- Days_missing_combined %>%
  pull(code) %>%
  unique()

Days_missing_combined %>%
  pull(name) %>%
  unique()

# Trusts excluded are mainly those seemed to start submitting their data late.
```

```{r}
# remove from the data
Sitrep_daily <- Sitrep_daily %>% 
   filter(!code %in% trusts_to_exclude)

dim(Sitrep_daily)  
```

```{r}
Sitrep_daily
# there remains the difference between when the total beds data starts and the length of stay data starts - will leave the data like this for now and adjust
# later if needed.

```

### Dealing with shorter gaps


